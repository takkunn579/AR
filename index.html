<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>AR Photo Booth</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <script src="https://aframe.io/releases/1.4.2/aframe.min.js"></script>
    <script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js"></script>
    <link href="//fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">

    <style>
        .ui {
            position: absolute;
            z-index: 100;
            bottom: 0;
            left: 0;
            width: 100%;
            height: auto;
            margin: 0;
            padding: 10px 15px 30px;
            text-align: center;
            box-sizing: border-box;
        }
        .ui a {
            display: inline-block;
            width: 60px;
            height: 60px;
            background-color: #ffffff;
            line-height: 100%;
            color: #303030;
            margin: 10px 3px;
            border-radius: 50%;
            position: relative;
            box-shadow: 0 2px 5px rgba(0,0,0,0.2);
        }
        .ui a i {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%,-50%);
            font-size: 28px;
        }
        .ui a:active {
            color: #ff0000;
        }
        #snap {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: contain; /* 画像の縦横比を維持 */
            background-color: rgba(0,0,0,0.85);
            z-index: 99; /* UI(z-index: 100)より背面に配置 */
            visibility: hidden;
        }
        .ui a.disabled {
            pointer-events: none;
            color: #cccccc;
            background-color: #f0f0f0;
        }
        #snap.visible {
            visibility: visible;
        }
    </style>
</head>

<body style="margin: 0; overflow: hidden;">

    <a-scene
        vr-mode-ui="enabled: false;"
        loading-screen="enabled: false;"
        renderer="logarithmicDepthBuffer: true; antialias: true; colorManagement: true; preserveDrawingBuffer: true;"
        arjs="trackingMethod: best; sourceType: webcam; debugUIEnabled: false;"
        embedded
        screenshot
    >
        <a-assets>
            <a-asset-item id="model1" src="assets/model1.glb"></a-asset-item>
            <a-asset-item id="model2" src="assets/model2.glb"></a-asset-item>
            <a-asset-item id="model3" src="assets/model3.glb"></a-asset-item>
        </a-assets>

        <a-marker type="pattern" url="assets/marker1.patt">
            <a-entity rotation="-90 0 0">
                <a-entity gltf-model="#model1" scale="0.5 0.5 0.5" position="0 0 0"></a-entity>
            </a-entity>
        </a-marker>

        <a-marker type="pattern" url="assets/marker2.patt">
            <a-entity rotation="-90 0 0">
                <a-entity gltf-model="#model2" scale="0.5 0.5 0.5" position="0 0 0"></a-entity>
            </a-entity>
        </a-marker>

        <a-marker type="pattern" url="assets/marker3.patt">
            <a-entity rotation="-90 0 0">
                <a-entity gltf-model="#model3" scale="0.5 0.5 0.5" position="0 0 0"></a-entity>
            </a-entity>
        </a-marker>

        <a-entity camera></a-entity>
    </a-scene>

    <img id="snap">
    <div class="ui">
        <a href="#" id="delete-photo" title="Delete Photo" class="disabled"><i class="material-icons">delete</i></a>
        <a href="#" id="take-photo" title="Take Photo"><i class="material-icons">photo_camera</i></a>
    </div>

    <script>
        const image = document.querySelector('#snap');
        const take_photo_btn = document.querySelector('#take-photo');
        const delete_photo_btn = document.querySelector('#delete-photo');
        const sceneEl = document.querySelector("a-scene");

        //スナップショットボタン
        take_photo_btn.addEventListener("click", function (e) {
            e.preventDefault();
            
            const video = document.querySelector('video');
            if (!video) return;

            const snap = takeSnapshot(video);
            if (!snap) return;

            //スナップショット表示
            image.setAttribute('src', snap);
            image.classList.add('visible');

            // 削除ボタンを有効化し、撮影ボタンを無効化
            delete_photo_btn.classList.remove("disabled");
            take_photo_btn.classList.add("disabled");
        });

        //削除ボタン
        delete_photo_btn.addEventListener("click", function(e){
            e.preventDefault();

            // スナップショットを隠す
            image.setAttribute('src', "");
            image.classList.remove("visible");

            // 削除ボタンを無効化し、撮影ボタンを有効化
            delete_photo_btn.classList.add("disabled");
            take_photo_btn.classList.remove("disabled");
        });

        //スナップショットを撮る関数
        function takeSnapshot(video) {
    try {
        const aSceneCanvas = sceneEl.components.screenshot.getCanvas("perspective");

        let videoNativeWidth = video.videoWidth;
        let videoNativeHeight = video.videoHeight;

        // 最終的な写真のサイズは、表示されているA-Frameのレンダリングキャンバスのサイズに合わせる
        // これがユーザーが見ているARの見た目と一致するはず
        const photoOutputWidth = aSceneCanvas.width;
        const photoOutputHeight = aSceneCanvas.height;

        if (photoOutputWidth === 0 || photoOutputHeight === 0 || videoNativeWidth === 0 || videoNativeHeight === 0) {
            alert("カメラの準備ができていません。少し待ってからもう一度お試しください。");
            return null;
        }

        const canvas = document.createElement("canvas");
        const context = canvas.getContext("2d");
        canvas.width = photoOutputWidth;
        canvas.height = photoOutputHeight;

        // --- 1. 背景となるビデオ映像を描画 ---
        // ここでの目標は、video要素の映像を、出力する写真のサイズに合わせて、
        // 縦横比を保ちつつ、かつ画面いっぱいに（または適切に）表示すること。
        // object-fit: cover のような振る舞いを実装

        const videoAspectRatio = videoNativeWidth / videoNativeHeight;
        const photoAspectRatio = photoOutputWidth / photoOutputHeight;

        let videoDrawX = 0;
        let videoDrawY = 0;
        let videoDrawWidth = photoOutputWidth;
        let videoDrawHeight = photoOutputHeight;

        if (videoAspectRatio > photoAspectRatio) {
            // ビデオが写真より横長なので、高さを合わせ、横はクロップ
            videoDrawHeight = photoOutputHeight;
            videoDrawWidth = photoOutputHeight * videoAspectRatio;
            videoDrawX = (photoOutputWidth - videoDrawWidth) / 2;
        } else {
            // ビデオが写真より縦長なので、幅を合わせ、縦はクロップ
            videoDrawWidth = photoOutputWidth;
            videoDrawHeight = photoOutputWidth / videoAspectRatio;
            videoDrawY = (photoOutputHeight - videoDrawHeight) / 2;
        }

        // 描画前に、ビデオ映像の向きを補正する
        // A-Frameのスクリーンショットは縦向きで取得されているはずだが、
        // video要素はネイティブな向き（横向き）でデータを持っているため、
        // 縦向きの写真に合わせて回転させる必要がある。
        
        // context.save();
        // context.translate(photoOutputWidth / 2, photoOutputHeight / 2);
        // context.rotate(Math.PI / 2); // 90度回転
        // context.drawImage(
        //     video, 
        //     -videoNativeHeight / 2, // 画面を90度回転させるので、ビデオのheightが新しいX方向
        //     -videoNativeWidth / 2,  // ビデオのwidthが新しいY方向
        //     videoNativeHeight,      // 描画するサイズも入れ替わる
        //     videoNativeWidth
        // );
        // context.restore();

        // AR.jsのカメラ映像は既にCSSで回転されているか、Three.jsによって調整されている可能性が高いので、
        // video要素をそのままcanvasに描画すると、横向きで描画されてしまう。
        // ここでvideoWidthとvideoHeightが交換されていれば、その交換された値を使うべき。
        // しかし、video.videoWidth/Heightは生のデータなので、描画時に調整が必要。
        // スマホの縦画面で、カメラの生データがwidth > heightの場合、
        // 描画時に90度回転して、描画先の縦横に合わせる。
        
        // ユーザーのデバイスが縦向きかどうか (CSSの `orientation: portrait` などで変わる可能性があるが、ここではビデオのraw dataで判断)
        const isDevicePortrait = window.matchMedia("(orientation: portrait)").matches;
        
        context.save();
        if (isDevicePortrait && videoNativeWidth > videoNativeHeight) {
            // デバイスが縦向きで、かつビデオの生データが横長の場合（＝縦画面で撮影中）
            context.translate(canvas.width / 2, canvas.height / 2);
            context.rotate(Math.PI / 2); // 90度回転
            // 回転後の中心座標に合わせるため、描画位置を調整
            context.drawImage(video, -canvas.height / 2, -canvas.width / 2, canvas.height, canvas.width);
        } else {
            // それ以外（横画面、またはデバイスの向きとビデオの生データが一致）
            context.drawImage(video, 0, 0, canvas.width, canvas.height);
        }
        context.restore();


        // --- 2. 3Dモデルのシーンを重ねる ---
        // A-Frameのレンダリング結果（aSceneCanvas）は、表示されている画面のサイズとアスペクト比に
        // 既に合わせられているはずなので、それをそのまま写真canvasに重ねる。
        // ただし、object-fit: contain のように、歪まずに最大限に収まるように調整する。

        const aSceneAspectRatio = aSceneCanvas.width / aSceneCanvas.height;
        let sceneDrawX = 0;
        let sceneDrawY = 0;
        let sceneDrawWidth = photoOutputWidth;
        let sceneDrawHeight = photoOutputHeight;

        if (aSceneAspectRatio > photoAspectRatio) {
            // シーンが写真より横長なので、幅を合わせ、高さを調整
            sceneDrawWidth = photoOutputWidth;
            sceneDrawHeight = photoOutputWidth / aSceneAspectRatio;
            sceneDrawY = (photoOutputHeight - sceneDrawHeight) / 2;
        } else {
            // シーンが写真より縦長なので、高さを合わせ、幅を調整
            sceneDrawHeight = photoOutputHeight;
            sceneDrawWidth = photoOutputHeight * aSceneAspectRatio;
            sceneDrawX = (photoOutputWidth - sceneDrawWidth) / 2;
        }
        
        context.drawImage(
            aSceneCanvas,
            0, 0, aSceneCanvas.width, aSceneCanvas.height, // ソース全体を使う
            sceneDrawX, sceneDrawY, sceneDrawWidth, sceneDrawHeight // デスティネーションに描画
        );
        
        return canvas.toDataURL('image/png');

    } catch (error) {
        console.error("撮影エラー:", error);
        alert("撮影中にエラーが発生しました。");
        return null;
    }
}
    </script>
</body>
</html>
